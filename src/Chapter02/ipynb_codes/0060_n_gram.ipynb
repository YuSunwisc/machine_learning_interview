{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 1. All necessary libraries"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Successfully imported all necessary libraries.\n"]}],"source":["import numpy as np\n","from typing import List, Tuple, Union\n","from collections import defaultdict, Counter\n","import random\n","\n","import unittest\n","import timeit\n","from memory_profiler import memory_usage\n","import time\n","\n","import sys\n","import os\n","\n","# Access the project root directory\n","project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..'))\n","sys.path.append(project_root)\n","\n","# Import the performance_test module from utils\n","from utils.performance_test import PerformanceTest\n","\n","print('Successfully imported all necessary libraries.')"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Define the Solution class"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Successfully defined the Solution class.\n"]}],"source":["class Solution:\n","    def __init__(self, N: int):\n","        \"\"\"\n","        Initialize the n-gram model with a specified n-gram size.\n","\n","        :param N: integer representing the size of n-gram (e.g., 2 for bigram, 3 for trigram)\n","        \"\"\"\n","        self.N = N\n","        self.ngram_counts = defaultdict(Counter)\n","\n","    def train(self, tokens: List[str]) -> None:\n","        \"\"\"\n","        Train the n-gram model by counting occurrences of n-grams in the input tokens.\n","\n","        :param tokens: List of tokens (words) representing the text\n","        \"\"\"\n","        # Check if N is valid\n","        if self.N > len(tokens) or self.N <= 0:\n","            raise ValueError(f\"Invalid n-gram size: {self.N}. It must be between 1 and the number of tokens.\")\n","\n","        for i in range(len(tokens) - self.N + 1):\n","            ngram = tuple(tokens[i:i + self.N - 1])\n","            next_word = tokens[i + self.N - 1]\n","            self.ngram_counts[ngram][next_word] += 1\n","\n","    def predict(self, context: Tuple[str]) -> Union[str, None]:\n","        \"\"\"\n","        Predict the next word based on the given context (previous n-1 words).\n","\n","        :param context: Tuple of strings representing the n-1 words context\n","        :return: The predicted next word or None if the context is not found\n","        \"\"\"\n","        if context in self.ngram_counts:\n","            possible_next_words = self.ngram_counts[context]\n","            result_list = random.choices(list(possible_next_words.keys()), weights=possible_next_words.values())\n","            # return the string, result_list is a list with one element\n","            return result_list[0]\n","        else:\n","            return \"Your context is not found in the training data.\"\n","\n","print('Successfully defined the Solution class.')"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Unit test"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["test_context_not_in_training_data (__main__.TestSolution)\n","Test predict with context not found in the training data. ... ok\n","test_empty_token_list (__main__.TestSolution)\n","Test train with an empty token list. ... ok\n","test_invalid_n_gram_size (__main__.TestSolution)\n","Test with invalid n-gram size (greater than token length). ... ok\n","test_large_n_gram_size (__main__.TestSolution)\n","Test with large n-gram size close to the length of tokens. ... ok\n","test_predict_on_empty_model (__main__.TestSolution)\n","Test predict on a model without any training data. ... ok\n","test_predict_valid_context (__main__.TestSolution)\n","Test predict with a valid context that is in the n-grams. ... ok\n","test_valid_input_train (__main__.TestSolution)\n","Test train with a valid token list. ... "]},{"name":"stdout","output_type":"stream","text":["Successfully defined the TestSolution class.\n"]},{"name":"stderr","output_type":"stream","text":["ok\n","\n","----------------------------------------------------------------------\n","Ran 7 tests in 0.006s\n","\n","OK\n"]}],"source":["class TestSolution(unittest.TestCase):\n","    def setUp(self):\n","        # Instantiate Solution with N=2 for bigram testing before each test\n","        self.solution = Solution(N=2)\n","\n","    # Type 1: Dimensions and Corner Cases\n","\n","    def test_invalid_n_gram_size(self):\n","        \"\"\"\n","        Test with invalid n-gram size (greater than token length).\n","        Expected result: ValueError\n","        \"\"\"\n","        # 1. Inputs\n","        input_tokens = [\"I\"]\n","\n","        # 2. Expected\n","        expected_exception = ValueError\n","\n","        # 3. Result\n","        with self.assertRaises(expected_exception):\n","            self.solution.train(input_tokens)\n","\n","    def test_context_not_in_training_data(self):\n","        \"\"\"\n","        Test predict with context not found in the training data.\n","        Expected result: \"Your context is not found in the training data.\"\n","        \"\"\"\n","        # 1. Inputs\n","        input_tokens = [\"hello\", \"world\"]\n","        input_context = (\"missing\", \"context\")\n","        self.solution.train(input_tokens)\n","\n","        # 2. Expected\n","        expected = \"Your context is not found in the training data.\"\n","\n","        # 3. Result\n","        result = self.solution.predict(input_context)\n","        self.assertEqual(result, expected)\n","\n","    # Type 2: Input Types\n","\n","    def test_valid_input_train(self):\n","        \"\"\"\n","        Test train with a valid token list.\n","        Expected result: n-grams are counted correctly.\n","        \"\"\"\n","        # 1. Inputs\n","        input_tokens = [\"I\", \"love\", \"deep\", \"learning\"]\n","\n","        # 2. Expected\n","        expected_ngrams = {\n","            (\"I\",): Counter({\"love\": 1}),\n","            (\"love\",): Counter({\"deep\": 1}),\n","            (\"deep\",): Counter({\"learning\": 1})\n","        }\n","\n","        # 3. Result\n","        self.solution.train(input_tokens)\n","        self.assertEqual(self.solution.ngram_counts, expected_ngrams)\n","\n","    def test_predict_valid_context(self):\n","        \"\"\"\n","        Test predict with a valid context that is in the n-grams.\n","        Expected result: Correct next word.\n","        \"\"\"\n","        # 1. Inputs\n","        input_tokens = [\"I\", \"enjoy\", \"NLP\", \"and\", \"ML\"]\n","        input_context = (\"I\",)\n","        self.solution.train(input_tokens)\n","\n","        # 2. Expected\n","        expected_words = [\"enjoy\"]\n","\n","        # 3. Result\n","        result = self.solution.predict(input_context)\n","        self.assertIn(result, expected_words)\n","\n","    # Type 3: Extreme Values\n","\n","    def test_large_n_gram_size(self):\n","        \"\"\"\n","        Test with large n-gram size close to the length of tokens.\n","        Expected result: model counts only one n-gram.\n","        \"\"\"\n","        # 1. Inputs\n","        self.solution = Solution(N=4)\n","        input_tokens = [\"machine\", \"learning\", \"is\", \"fun\"]\n","\n","        # 2. Expected\n","        expected_ngrams = {(\"machine\", \"learning\", \"is\"): Counter({\"fun\": 1})}\n","\n","        # 3. Result\n","        self.solution.train(input_tokens)\n","        self.assertEqual(self.solution.ngram_counts, expected_ngrams)\n","\n","    def test_empty_token_list(self):\n","        \"\"\"\n","        Test train with an empty token list.\n","        Expected result: ValueError\n","        \"\"\"\n","        # 1. Inputs\n","        input_tokens = []\n","\n","        # 2. Expected\n","        expected_exception = ValueError\n","\n","        # 3. Result\n","        with self.assertRaises(expected_exception):\n","            self.solution.train(input_tokens)\n","\n","    def test_predict_on_empty_model(self):\n","        \"\"\"\n","        Test predict on a model without any training data.\n","        Expected result: \"Your context is not found in the training data.\"\n","        \"\"\"\n","        # 1. Inputs\n","        input_context = (\"I\", \"love\")\n","\n","        # 2. Expected\n","        expected = \"Your context is not found in the training data.\"\n","\n","        # 3. Result\n","        result = self.solution.predict(input_context)\n","        self.assertEqual(result, expected)\n","\n","def run_unit_tests():\n","    \"\"\"\n","    Runs all unit tests for the Solution class.\n","    Uses TextTestRunner with verbosity level 2 for detailed output.\n","    \"\"\"\n","    runner = unittest.TextTestRunner(verbosity=2)\n","    suite = unittest.TestLoader().loadTestsFromTestCase(TestSolution)\n","    runner.run(suite)\n","\n","print('Successfully defined the TestSolution class.')\n","run_unit_tests()\n"]},{"cell_type":"markdown","metadata":{},"source":["# 4. Performance test"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Successfully defined the PerformanceTest class.\n"]}],"source":["def run_performance_tests():\n","    solution = Solution(N=3)\n","    tokens = [\"I\", \"love\", \"natural\", \"language\", \"processing\", \"and\", \"I\", \"love\", \"machine\", \"learning\"]\n","    context = (\"I\", \"love\")\n","    # Estimate time complexity\n","    PerformanceTest.estimate_time_complexity(solution.train, tokens)\n","    PerformanceTest.estimate_time_complexity(solution.predict, context)\n","\n","    # Estimate space complexity\n","    PerformanceTest.estimate_space_complexity(solution.train, tokens)\n","    PerformanceTest.estimate_space_complexity(solution.predict, context)\n","print('Successfully defined the PerformanceTest class.')"]},{"cell_type":"markdown","metadata":{},"source":["# 5. Main"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["test_context_not_in_training_data (__main__.TestSolution)\n","Test predict with context not found in the training data. ... ok\n","test_empty_token_list (__main__.TestSolution)\n","Test train with an empty token list. ... ok\n","test_invalid_n_gram_size (__main__.TestSolution)\n","Test with invalid n-gram size (greater than token length). ... ok\n","test_large_n_gram_size (__main__.TestSolution)\n","Test with large n-gram size close to the length of tokens. ... ok\n","test_predict_on_empty_model (__main__.TestSolution)\n","Test predict on a model without any training data. ... ok\n","test_predict_valid_context (__main__.TestSolution)\n","Test predict with a valid context that is in the n-grams. ... ok\n","test_valid_input_train (__main__.TestSolution)\n","Test train with a valid token list. ... ok\n","\n","----------------------------------------------------------------------\n","Ran 7 tests in 0.004s\n","\n","OK\n"]},{"name":"stdout","output_type":"stream","text":["\n","----------------------------------------------------------------------------------------------------\n","\n","Average execution time over 10 runs: 0.000010 seconds\n","Average execution time over 10 runs: 0.000005 seconds\n","Peak memory usage: 0.179688 MiB\n","Peak memory usage: 0.218750 MiB\n"]}],"source":["\n","if __name__ == \"__main__\":\n","    # Run unit tests\n","    # unittest.main(argv=['first-arg-is-ignored'], exit=False)\n","    run_unit_tests()\n","\n","    # Add sleep and separator\n","    print(\"\\n\" + \"-\" * 100 + \"\\n\")\n","    time.sleep(1)\n","\n","    # Performance tests\n","    run_performance_tests()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"}},"nbformat":4,"nbformat_minor":2}
