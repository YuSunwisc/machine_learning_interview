{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d086421-7dcc-4020-9c49-3d42025386cc",
   "metadata": {},
   "source": [
    "# 1. scrapy\n",
    "\n",
    "适合静态抓取网页"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1f78883-44d7-4e62-8f18-de2f85d01593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 16:13:17 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2024-11-22 16:13:17 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.9.20 (main, Oct  3 2024, 02:24:59) - [Clang 14.0.6 ], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform macOS-15.1.1-arm64-arm-64bit\n",
      "2024-11-22 16:13:17 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2024-11-22 16:13:17 [scrapy.extensions.telnet] INFO: Telnet Password: 302695eb2e4ff21f\n",
      "2024-11-22 16:13:17 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2024-11-22 16:13:17 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 'INFO'}\n",
      "2024-11-22 16:13:17 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2024-11-22 16:13:17 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2024-11-22 16:13:17 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2024-11-22 16:13:17 [scrapy.core.engine] INFO: Spider opened\n",
      "2024-11-22 16:13:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2024-11-22 16:13:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2024-11-22 16:13:19 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2024-11-22 16:13:19 [scrapy.extensions.feedexport] INFO: Stored json feed (1 items) in: scrapy_output.json\n",
      "2024-11-22 16:13:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 214,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 18417,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 1.788569,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2024, 11, 23, 0, 13, 19, 183235, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 68309,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 1,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 11,\n",
      " 'memusage/max': 92717056,\n",
      " 'memusage/startup': 92717056,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2024, 11, 23, 0, 13, 17, 394666, tzinfo=datetime.timezone.utc)}\n",
      "2024-11-22 16:13:19 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "from scrapy import Spider\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class ScrapySpider(Spider):\n",
    "    name = \"scrapy_spider\"\n",
    "    start_urls = [\"https://math.wisc.edu\"]  # 替换为你的目标 URL\n",
    "\n",
    "    def parse(self, response):\n",
    "        # 提取页面标题\n",
    "        page_title = response.xpath(\"//title/text()\").get()\n",
    "        yield {\"title\": page_title}\n",
    "\n",
    "# 在 Jupyter 中运行 Scrapy 爬虫\n",
    "process = CrawlerProcess(settings={\n",
    "    \"FEEDS\": {\"scrapy_output.json\": {\"format\": \"json\"}},  # 保存结果到 JSON 文件\n",
    "    \"LOG_LEVEL\": \"INFO\",\n",
    "})\n",
    "\n",
    "process.crawl(ScrapySpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03992512-739a-4a66-ac9b-4518db3aa2df",
   "metadata": {},
   "source": [
    "# 2. selenium\n",
    "适合动态抓取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ec1eacf-8073-40a5-b2b0-f459408d9019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/YuSun/anaconda3/envs/pytorch/lib/python3.9/site-packages (4.26.1)\n",
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /Users/YuSun/anaconda3/envs/pytorch/lib/python3.9/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/YuSun/anaconda3/envs/pytorch/lib/python3.9/site-packages (from selenium) (0.27.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/YuSun/anaconda3/envs/pytorch/lib/python3.9/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/YuSun/anaconda3/envs/pytorch/lib/python3.9/site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /Users/YuSun/anaconda3/envs/pytorch/lib/python3.9/site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /Users/YuSun/anaconda3/envs/pytorch/lib/python3.9/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: requests in /Users/YuSun/anaconda3/envs/pytorch/lib/python3.9/site-packages (from webdriver-manager) (2.32.3)\n",
      "Collecting python-dotenv (from webdriver-manager)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: packaging in /Users/YuSun/anaconda3/envs/pytorch/lib/python3.9/site-packages (from webdriver-manager) (24.2)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Users/YuSun/anaconda3/envs/pytorch/lib/python3.9/site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/YuSun/anaconda3/envs/pytorch/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Users/YuSun/anaconda3/envs/pytorch/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Requirement already satisfied: outcome in /Users/YuSun/anaconda3/envs/pytorch/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Users/YuSun/anaconda3/envs/pytorch/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /Users/YuSun/anaconda3/envs/pytorch/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/YuSun/anaconda3/envs/pytorch/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /Users/YuSun/anaconda3/envs/pytorch/lib/python3.9/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/YuSun/anaconda3/envs/pytorch/lib/python3.9/site-packages (from requests->webdriver-manager) (3.4.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/YuSun/anaconda3/envs/pytorch/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv, webdriver-manager\n",
      "Successfully installed python-dotenv-1.0.1 webdriver-manager-4.0.2\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium webdriver-manager\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acb8e05a-a964-49fa-a845-7df1a1d96efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 16:29:33 [WDM] INFO: ====== WebDriver manager ======\n",
      "2024-11-22 16:29:38 [WDM] INFO: Get LATEST chromedriver version for google-chrome\n",
      "2024-11-22 16:29:39 [WDM] INFO: Get LATEST chromedriver version for google-chrome\n",
      "2024-11-22 16:29:39 [WDM] INFO: There is no [mac64] chromedriver \"130.0.6723.116\" for browser google-chrome \"130.0.6723\" in cache\n",
      "2024-11-22 16:29:39 [WDM] INFO: Get LATEST chromedriver version for google-chrome\n",
      "2024-11-22 16:29:39 [WDM] INFO: WebDriver version 130.0.6723.116 selected\n",
      "2024-11-22 16:29:39 [WDM] INFO: Modern chrome version https://storage.googleapis.com/chrome-for-testing-public/130.0.6723.116/mac-arm64/chromedriver-mac-arm64.zip\n",
      "2024-11-22 16:29:39 [WDM] INFO: About to download new driver from https://storage.googleapis.com/chrome-for-testing-public/130.0.6723.116/mac-arm64/chromedriver-mac-arm64.zip\n",
      "2024-11-22 16:29:39 [WDM] INFO: Driver downloading response is 200\n",
      "2024-11-22 16:29:44 [WDM] INFO: Get LATEST chromedriver version for google-chrome\n",
      "2024-11-22 16:29:44 [WDM] INFO: Driver has been saved in cache [/Users/YuSun/.wdm/drivers/chromedriver/mac64/130.0.6723.116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL stock price: 229.87\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"\n",
    "    初始化 WebDriver。\n",
    "    使用 WebDriver Manager 动态管理 ChromeDriver 路径。\n",
    "    \"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # 无头模式\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "    service = Service(ChromeDriverManager().install())  # 自动管理 ChromeDriver\n",
    "    return webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "def get_stock_price(stock_symbol):\n",
    "    \"\"\"\n",
    "    获取指定股票代码的价格。\n",
    "    参数:\n",
    "        stock_symbol (str): 股票代码，例如 \"AAPL\"。\n",
    "    \"\"\"\n",
    "    driver = setup_driver()\n",
    "    try:\n",
    "        # 打开 Google 搜索\n",
    "        driver.get(\"https://www.google.com\")\n",
    "        time.sleep(2)\n",
    "\n",
    "        # 在搜索框中输入股票代码并搜索\n",
    "        search_box = driver.find_element(By.NAME, \"q\")\n",
    "        search_box.send_keys(f\"{stock_symbol} stock price\")\n",
    "        search_box.send_keys(Keys.RETURN)\n",
    "        time.sleep(3)\n",
    "\n",
    "        # 提取股票价格\n",
    "        price_element = driver.find_element(By.XPATH, \"//span[@jsname='vWLAgc']\")  # 根据页面结构选择正确的 XPath\n",
    "        stock_price = price_element.text\n",
    "\n",
    "        # 打印结果\n",
    "        print(f\"{stock_symbol} stock price: {stock_price}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while fetching stock price for {stock_symbol}: {e}\")\n",
    "    finally:\n",
    "        # 确保关闭浏览器\n",
    "        driver.quit()\n",
    "\n",
    "# 示例：获取苹果公司（AAPL）的股价\n",
    "get_stock_price(\"AAPL\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
